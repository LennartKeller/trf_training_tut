
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Experimental Design &#8212; A comparing guide to train language models with Python.</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Prerequisites" href="Prerequisites.html" />
    <link rel="prev" title="The Huggingface ecosystem" href="HuggingfaceEcosystem.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">A comparing guide to train language models with Python.</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Home.html">
   Preface
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="HuggingfaceEcosystem.html">
   The Huggingface ecosystem
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Experimental Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Prerequisites.html">
   Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="HuggingFaceTrainer.html">
   Huggingface Trainer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PyTorchLightning.html">
   PyTorch Lightning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Poutyne.html">
   Poutyne
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ExperimentalResults.html">
   Experimental Results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Conclusion.html">
   Conclusion
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Experiment.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/LennartKeller/trf_training_tut"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/LennartKeller/trf_training_tut/issues/new?title=Issue%20on%20page%20%2FExperiment.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#task">
   Task
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metrics">
   Metrics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset">
   Dataset
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="experimental-design">
<h1>Experimental Design<a class="headerlink" href="#experimental-design" title="Permalink to this headline">¶</a></h1>
<div class="section" id="task">
<h2>Task<a class="headerlink" href="#task" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default" id="fig-task-desc">
<img alt="_images/GraphicsTrfTut.png" src="_images/GraphicsTrfTut.png" />
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Visualization of the sentence ordering task.</span><a class="headerlink" href="#fig-task-desc" title="Permalink to this image">¶</a></p>
</div>
<p>To compare the frameworks, we will implement the same experiment with each of them.
The task of the experiment is a critical choice since training a model on a standard objective like text- or token classification would not require much customization. Also, it would put the Huggingface Trainer into an advantageous position because it supports such tasks out of the box.
To ensure a fair comparison, we chose another quite exotic objective: Sentence Ordering.
Our goal is to train a model to predict the correct order of a sequence of shuffled sentences.
This task seemed right for two reasons.
Firstly, it can be implemented with a standard Huggingface model but requires a custom loss function.
Secondly, the task falls into the category of self-supervised learning. So it is possible to generate training and test data from unstructured text data in an effortless manner.
Besides these practical implications, the objective is interesting because it can measure the causal coherence of texts. For example, to assess whether the coherence of actions varies between different text types or genres.</p>
<p>But how do we achieve this task?
There are various methods proposed ranging from relatively simple approaches like applying ranking-loss functions (<span id="id1">Zhu <em>et al.</em> [<a class="reference internal" href="Bibliography.html#id7">2021</a>]</span>) to rather complex ones that learn a graph representation of the sentences and then use topological sorting to extract the correct order of the sentences (<span id="id2">Yin <em>et al.</em> [<a class="reference internal" href="Bibliography.html#id6">2019</a>]</span>).
Because we do not care much about achieving state-of-the-art results, we opt for one of the most straightforward approaches and frame it as a regression task.
<a class="reference internal" href="#fig-task-desc"><span class="std std-numref">Fig. 1</span></a> visualizes this approach.
The model should output a regression score for each sentence in the input, indicating its position in the original text.
Therefore, a special token is added as a prefix to each sentence. These tokens act as our targets while training, and they should output a value near to the original index of the sentence in the correct ordered text.
The loss is measured using the Mean-Squared-Error objective
The target value for each sentence token is not normalized and ranges from 0 to <span class="math notranslate nohighlight">\(N\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the number of sentences in the input sequence.
Another even more straightforward approach would be to add a final layer to the network with a fixed size of neurons (one for each sentence), but this would mean we had to know the number of sentences in the input beforehand, which would harm the usability of the model.</p>
<p>Using regression for sentence ordering is not a novel approach.
It was first proposed by <span id="id3">McClure <em>et al.</em> [<a class="reference internal" href="Bibliography.html#id8">2018</a>]</span>, who used it with CNNs and LSTMs and was later on employed as a baseline by <span id="id4">Kumar <em>et al.</em> [<a class="reference internal" href="Bibliography.html#id9">2020</a>]</span> with BERT.
However, in both cases, the authors used the neural network to encode all sentences independently and then fed the sentence embeddings into a regression component.
But we will feed the whole shuffled text into the network. This strategy allows the model to attend to all sentences and their tokens simultaneously, giving it more context to decide on the correct order.
Also, both other authors normalized the values of the regression target to be in the range of <span class="math notranslate nohighlight">\(-1,1\)</span> or <span class="math notranslate nohighlight">\(0,1\)</span>, respectively. However, after some brief experiments, we dropped the normalization because it did not yield any benefits. But, in general, dropping the normalization is only feasible with a dataset with a fixed number of sentences because otherwise, it could skew the loss in favor of short texts.</p>
<p>Since the position of the target tokens in the input sequences differs, we need our language model to output one logit for each token. Two Huggingface model variants return a suitable output <code class="docutils literal notranslate"><span class="pre">&lt;...ModelType...&gt;ForTokenClassification</span></code> or <code class="docutils literal notranslate"><span class="pre">&lt;...ModelType...&gt;ForQuestionAnswering</span></code>. We chose the first one, but all the code in the following section should also run when employing a model with a question-answering head.</p>
</div>
<div class="section" id="metrics">
<h2>Metrics<a class="headerlink" href="#metrics" title="Permalink to this headline">¶</a></h2>
<p>To measure the performance of our model, we use two metrics.</p>
<p><strong>Accuracy</strong></p>
<p>Accuracy measures how many sentences per instance are indexed correctly.
Accuracy gives a rough estimate of how well the model performs, but it can paint a misleading picture since it does not fully account for our task’s ranking aspect.
For example, suppose that the model would correctly predict that sentence <span class="math notranslate nohighlight">\(B\)</span> follows sentence <span class="math notranslate nohighlight">\(A\)</span> and expects them to be at position <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span> in the total ordering.
But in reality, they are the last sentences of the text. So, in this case, the accuracy would be <span class="math notranslate nohighlight">\(0\)</span> (assuming that all other predictions were also wrong).</p>
<p><strong>Kendalls Tau</strong></p>
<p>In contrast to accuracy, Kendall Tau is a ranking correlation coefficient that accounts for partially correct parts of a ranking.
It measures the difference between pairs of sentences correctly predicted as following and all other wrongly predicted pairs.
This value is further corrected for the chance of randomly predicting correct pairs of sentences by dividing it by the total number of unique ways to pick two sentences from the sequence.</p>
<div class="math notranslate nohighlight">
\[
\tau_{\textrm{Kendall}} = \frac{\#\textrm{Correctly predicted pairs of sentences} - \#\textrm{Wrongly predicted pairs of sentences}}{\binom{N}{2}}
\]</div>
</div>
<div class="section" id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h2>
<p>We use the 2017 version of the ROCStories dataset by <span id="id5">Mostafazadeh <em>et al.</em> [<a class="reference internal" href="Bibliography.html#id2">2016</a>]</span>. It contains 52.665 short stories with a fixed length of five sentences. This dataset is commonly used in the literature because its stories mainly depict concrete actions with a clear causal order, making them relatively simple to understand without leaving much space for ambiguities. This property makes it a good fit for testing the general capabilities of language models on this task.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Even though the ROCStories dataset is freely available to the public, anyone who uses it must submit contact data. So the dataset itself is not included in the Github-Repository and must be downloaded independently from <a class="reference external" href="https://cs.rochester.edu/nlp/rocstories/">https://cs.rochester.edu/nlp/rocstories/</a></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In addition, we tested the same experimental setup on a dataset of sentences sampled from german short novels (Novellen) without much success. An insufficient sampling of subparts of the texts is the most likely reason for this failure.
Applying this task to all kinds of different textual domains can be a fruitful question itself but lies outside the scope of this work.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="HuggingfaceEcosystem.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">The Huggingface ecosystem</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="Prerequisites.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Prerequisites</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Lennart Keller<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>