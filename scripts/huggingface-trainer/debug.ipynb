{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8529be47-8781-4f40-85bc-fa64b7e2ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b56d42f-9fb1-43bd-8d34-a4e6b874dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BertForMultiHeadModel\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc547f5-f268-45d8-be38-1ea9fbb13e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultiHeadModel were not initialized from the model checkpoint at test/checkpoint-4000 and are newly initialized: ['.bert.embeddings.position_ids', '.bert.embeddings.word_embeddings.weight', '.bert.embeddings.position_embeddings.weight', '.bert.embeddings.token_type_embeddings.weight', '.bert.embeddings.LayerNorm.weight', '.bert.embeddings.LayerNorm.bias', '.bert.encoder.layer.0.attention.self.query.weight', '.bert.encoder.layer.0.attention.self.query.bias', '.bert.encoder.layer.0.attention.self.key.weight', '.bert.encoder.layer.0.attention.self.key.bias', '.bert.encoder.layer.0.attention.self.value.weight', '.bert.encoder.layer.0.attention.self.value.bias', '.bert.encoder.layer.0.attention.output.dense.weight', '.bert.encoder.layer.0.attention.output.dense.bias', '.bert.encoder.layer.0.attention.output.LayerNorm.weight', '.bert.encoder.layer.0.attention.output.LayerNorm.bias', '.bert.encoder.layer.0.intermediate.dense.weight', '.bert.encoder.layer.0.intermediate.dense.bias', '.bert.encoder.layer.0.output.dense.weight', '.bert.encoder.layer.0.output.dense.bias', '.bert.encoder.layer.0.output.LayerNorm.weight', '.bert.encoder.layer.0.output.LayerNorm.bias', '.bert.encoder.layer.1.attention.self.query.weight', '.bert.encoder.layer.1.attention.self.query.bias', '.bert.encoder.layer.1.attention.self.key.weight', '.bert.encoder.layer.1.attention.self.key.bias', '.bert.encoder.layer.1.attention.self.value.weight', '.bert.encoder.layer.1.attention.self.value.bias', '.bert.encoder.layer.1.attention.output.dense.weight', '.bert.encoder.layer.1.attention.output.dense.bias', '.bert.encoder.layer.1.attention.output.LayerNorm.weight', '.bert.encoder.layer.1.attention.output.LayerNorm.bias', '.bert.encoder.layer.1.intermediate.dense.weight', '.bert.encoder.layer.1.intermediate.dense.bias', '.bert.encoder.layer.1.output.dense.weight', '.bert.encoder.layer.1.output.dense.bias', '.bert.encoder.layer.1.output.LayerNorm.weight', '.bert.encoder.layer.1.output.LayerNorm.bias', '.bert.encoder.layer.2.attention.self.query.weight', '.bert.encoder.layer.2.attention.self.query.bias', '.bert.encoder.layer.2.attention.self.key.weight', '.bert.encoder.layer.2.attention.self.key.bias', '.bert.encoder.layer.2.attention.self.value.weight', '.bert.encoder.layer.2.attention.self.value.bias', '.bert.encoder.layer.2.attention.output.dense.weight', '.bert.encoder.layer.2.attention.output.dense.bias', '.bert.encoder.layer.2.attention.output.LayerNorm.weight', '.bert.encoder.layer.2.attention.output.LayerNorm.bias', '.bert.encoder.layer.2.intermediate.dense.weight', '.bert.encoder.layer.2.intermediate.dense.bias', '.bert.encoder.layer.2.output.dense.weight', '.bert.encoder.layer.2.output.dense.bias', '.bert.encoder.layer.2.output.LayerNorm.weight', '.bert.encoder.layer.2.output.LayerNorm.bias', '.bert.encoder.layer.3.attention.self.query.weight', '.bert.encoder.layer.3.attention.self.query.bias', '.bert.encoder.layer.3.attention.self.key.weight', '.bert.encoder.layer.3.attention.self.key.bias', '.bert.encoder.layer.3.attention.self.value.weight', '.bert.encoder.layer.3.attention.self.value.bias', '.bert.encoder.layer.3.attention.output.dense.weight', '.bert.encoder.layer.3.attention.output.dense.bias', '.bert.encoder.layer.3.attention.output.LayerNorm.weight', '.bert.encoder.layer.3.attention.output.LayerNorm.bias', '.bert.encoder.layer.3.intermediate.dense.weight', '.bert.encoder.layer.3.intermediate.dense.bias', '.bert.encoder.layer.3.output.dense.weight', '.bert.encoder.layer.3.output.dense.bias', '.bert.encoder.layer.3.output.LayerNorm.weight', '.bert.encoder.layer.3.output.LayerNorm.bias', '.bert.encoder.layer.4.attention.self.query.weight', '.bert.encoder.layer.4.attention.self.query.bias', '.bert.encoder.layer.4.attention.self.key.weight', '.bert.encoder.layer.4.attention.self.key.bias', '.bert.encoder.layer.4.attention.self.value.weight', '.bert.encoder.layer.4.attention.self.value.bias', '.bert.encoder.layer.4.attention.output.dense.weight', '.bert.encoder.layer.4.attention.output.dense.bias', '.bert.encoder.layer.4.attention.output.LayerNorm.weight', '.bert.encoder.layer.4.attention.output.LayerNorm.bias', '.bert.encoder.layer.4.intermediate.dense.weight', '.bert.encoder.layer.4.intermediate.dense.bias', '.bert.encoder.layer.4.output.dense.weight', '.bert.encoder.layer.4.output.dense.bias', '.bert.encoder.layer.4.output.LayerNorm.weight', '.bert.encoder.layer.4.output.LayerNorm.bias', '.bert.encoder.layer.5.attention.self.query.weight', '.bert.encoder.layer.5.attention.self.query.bias', '.bert.encoder.layer.5.attention.self.key.weight', '.bert.encoder.layer.5.attention.self.key.bias', '.bert.encoder.layer.5.attention.self.value.weight', '.bert.encoder.layer.5.attention.self.value.bias', '.bert.encoder.layer.5.attention.output.dense.weight', '.bert.encoder.layer.5.attention.output.dense.bias', '.bert.encoder.layer.5.attention.output.LayerNorm.weight', '.bert.encoder.layer.5.attention.output.LayerNorm.bias', '.bert.encoder.layer.5.intermediate.dense.weight', '.bert.encoder.layer.5.intermediate.dense.bias', '.bert.encoder.layer.5.output.dense.weight', '.bert.encoder.layer.5.output.dense.bias', '.bert.encoder.layer.5.output.LayerNorm.weight', '.bert.encoder.layer.5.output.LayerNorm.bias', '.bert.encoder.layer.6.attention.self.query.weight', '.bert.encoder.layer.6.attention.self.query.bias', '.bert.encoder.layer.6.attention.self.key.weight', '.bert.encoder.layer.6.attention.self.key.bias', '.bert.encoder.layer.6.attention.self.value.weight', '.bert.encoder.layer.6.attention.self.value.bias', '.bert.encoder.layer.6.attention.output.dense.weight', '.bert.encoder.layer.6.attention.output.dense.bias', '.bert.encoder.layer.6.attention.output.LayerNorm.weight', '.bert.encoder.layer.6.attention.output.LayerNorm.bias', '.bert.encoder.layer.6.intermediate.dense.weight', '.bert.encoder.layer.6.intermediate.dense.bias', '.bert.encoder.layer.6.output.dense.weight', '.bert.encoder.layer.6.output.dense.bias', '.bert.encoder.layer.6.output.LayerNorm.weight', '.bert.encoder.layer.6.output.LayerNorm.bias', '.bert.encoder.layer.7.attention.self.query.weight', '.bert.encoder.layer.7.attention.self.query.bias', '.bert.encoder.layer.7.attention.self.key.weight', '.bert.encoder.layer.7.attention.self.key.bias', '.bert.encoder.layer.7.attention.self.value.weight', '.bert.encoder.layer.7.attention.self.value.bias', '.bert.encoder.layer.7.attention.output.dense.weight', '.bert.encoder.layer.7.attention.output.dense.bias', '.bert.encoder.layer.7.attention.output.LayerNorm.weight', '.bert.encoder.layer.7.attention.output.LayerNorm.bias', '.bert.encoder.layer.7.intermediate.dense.weight', '.bert.encoder.layer.7.intermediate.dense.bias', '.bert.encoder.layer.7.output.dense.weight', '.bert.encoder.layer.7.output.dense.bias', '.bert.encoder.layer.7.output.LayerNorm.weight', '.bert.encoder.layer.7.output.LayerNorm.bias', '.bert.encoder.layer.8.attention.self.query.weight', '.bert.encoder.layer.8.attention.self.query.bias', '.bert.encoder.layer.8.attention.self.key.weight', '.bert.encoder.layer.8.attention.self.key.bias', '.bert.encoder.layer.8.attention.self.value.weight', '.bert.encoder.layer.8.attention.self.value.bias', '.bert.encoder.layer.8.attention.output.dense.weight', '.bert.encoder.layer.8.attention.output.dense.bias', '.bert.encoder.layer.8.attention.output.LayerNorm.weight', '.bert.encoder.layer.8.attention.output.LayerNorm.bias', '.bert.encoder.layer.8.intermediate.dense.weight', '.bert.encoder.layer.8.intermediate.dense.bias', '.bert.encoder.layer.8.output.dense.weight', '.bert.encoder.layer.8.output.dense.bias', '.bert.encoder.layer.8.output.LayerNorm.weight', '.bert.encoder.layer.8.output.LayerNorm.bias', '.bert.encoder.layer.9.attention.self.query.weight', '.bert.encoder.layer.9.attention.self.query.bias', '.bert.encoder.layer.9.attention.self.key.weight', '.bert.encoder.layer.9.attention.self.key.bias', '.bert.encoder.layer.9.attention.self.value.weight', '.bert.encoder.layer.9.attention.self.value.bias', '.bert.encoder.layer.9.attention.output.dense.weight', '.bert.encoder.layer.9.attention.output.dense.bias', '.bert.encoder.layer.9.attention.output.LayerNorm.weight', '.bert.encoder.layer.9.attention.output.LayerNorm.bias', '.bert.encoder.layer.9.intermediate.dense.weight', '.bert.encoder.layer.9.intermediate.dense.bias', '.bert.encoder.layer.9.output.dense.weight', '.bert.encoder.layer.9.output.dense.bias', '.bert.encoder.layer.9.output.LayerNorm.weight', '.bert.encoder.layer.9.output.LayerNorm.bias', '.bert.encoder.layer.10.attention.self.query.weight', '.bert.encoder.layer.10.attention.self.query.bias', '.bert.encoder.layer.10.attention.self.key.weight', '.bert.encoder.layer.10.attention.self.key.bias', '.bert.encoder.layer.10.attention.self.value.weight', '.bert.encoder.layer.10.attention.self.value.bias', '.bert.encoder.layer.10.attention.output.dense.weight', '.bert.encoder.layer.10.attention.output.dense.bias', '.bert.encoder.layer.10.attention.output.LayerNorm.weight', '.bert.encoder.layer.10.attention.output.LayerNorm.bias', '.bert.encoder.layer.10.intermediate.dense.weight', '.bert.encoder.layer.10.intermediate.dense.bias', '.bert.encoder.layer.10.output.dense.weight', '.bert.encoder.layer.10.output.dense.bias', '.bert.encoder.layer.10.output.LayerNorm.weight', '.bert.encoder.layer.10.output.LayerNorm.bias', '.bert.encoder.layer.11.attention.self.query.weight', '.bert.encoder.layer.11.attention.self.query.bias', '.bert.encoder.layer.11.attention.self.key.weight', '.bert.encoder.layer.11.attention.self.key.bias', '.bert.encoder.layer.11.attention.self.value.weight', '.bert.encoder.layer.11.attention.self.value.bias', '.bert.encoder.layer.11.attention.output.dense.weight', '.bert.encoder.layer.11.attention.output.dense.bias', '.bert.encoder.layer.11.attention.output.LayerNorm.weight', '.bert.encoder.layer.11.attention.output.LayerNorm.bias', '.bert.encoder.layer.11.intermediate.dense.weight', '.bert.encoder.layer.11.intermediate.dense.bias', '.bert.encoder.layer.11.output.dense.weight', '.bert.encoder.layer.11.output.dense.bias', '.bert.encoder.layer.11.output.LayerNorm.weight', '.bert.encoder.layer.11.output.LayerNorm.bias', '.bert.pooler.dense.weight', '.bert.pooler.dense.bias', '.classification_head.weight', '.classification_head.bias', '.multilabel_classification_head.weight', '.multilabel_classification_head.bias', '.regression_head.weight', '.regression_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForMultiHeadModel.from_pretrained('test/checkpoint-4000')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-german-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f373eb2-0988-4a0e-a7b2-34fddc3eb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_val = pd.read_json('../data/imdb_val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0769f0-5fb2-44ff-a802-e31fef5be298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text              Bisher bei The Americans... - Ihre Großtante? ...\n",
      "IMDB_ID                                                   tt3459862\n",
      "genre                                              [Crime, Mystery]\n",
      "year                                                           2014\n",
      "duration                                                         45\n",
      "titleType                                                 tvEpisode\n",
      "primaryTitle                                            The Walk-In\n",
      "isAdult                                                           0\n",
      "runtimeMinutes                                                   45\n",
      "averageRating                                                   8.1\n",
      "numVotes                                                       1149\n",
      "Name: 0, dtype: object\n",
      "Bisher bei\n",
      "tensor([0.4289, 0.5711])\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6412, 0.6368, 0.6175]),\n",
      "indices=tensor([12, 10,  3]))\n",
      "tensor([0.1659])\n",
      "########################################################################################################################################################################################################\n",
      "text              Was geht, Leute? Hier sind Rickie, Melvin und ...\n",
      "IMDB_ID                                                   tt1986953\n",
      "genre                                              [Horror, Sci-Fi]\n",
      "year                                                           2012\n",
      "duration                                                         87\n",
      "titleType                                                     movie\n",
      "primaryTitle                                             Storage 24\n",
      "isAdult                                                           0\n",
      "runtimeMinutes                                                   87\n",
      "averageRating                                                   4.4\n",
      "numVotes                                                       6399\n",
      "Name: 1, dtype: object\n",
      "Was geht, \n",
      "tensor([0.4386, 0.5614])\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6527, 0.6410, 0.6075]),\n",
      "indices=tensor([12, 10,  3]))\n",
      "tensor([0.1906])\n",
      "########################################################################################################################################################################################################\n",
      "text              BELLE UND SEBASTIAN Siehst du diesen Pfotenabd...\n",
      "IMDB_ID                                                   tt3146360\n",
      "genre                                           [Adventure, Family]\n",
      "year                                                           2013\n",
      "duration                                                        104\n",
      "titleType                                                     movie\n",
      "primaryTitle                                      Belle & Sebastian\n",
      "isAdult                                                           0\n",
      "runtimeMinutes                                                  104\n",
      "averageRating                                                   6.9\n",
      "numVotes                                                       4152\n",
      "Name: 2, dtype: object\n",
      "BELLE UND \n",
      "tensor([0.4435, 0.5565])\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6469, 0.6429, 0.6133]),\n",
      "indices=tensor([10, 12,  3]))\n",
      "tensor([0.1978])\n",
      "########################################################################################################################################################################################################\n",
      "text              Bisher bei The Americans... Hör zu, Kimmy, die...\n",
      "IMDB_ID                                                   tt4259460\n",
      "genre                                              [Crime, Mystery]\n",
      "year                                                           2015\n",
      "duration                                                         47\n",
      "titleType                                                 tvEpisode\n",
      "primaryTitle                                             Born Again\n",
      "isAdult                                                           0\n",
      "runtimeMinutes                                                   47\n",
      "averageRating                                                   8.3\n",
      "numVotes                                                        968\n",
      "Name: 3, dtype: object\n",
      "Bisher bei\n",
      "tensor([0.4266, 0.5734])\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6505, 0.6406, 0.6140]),\n",
      "indices=tensor([12, 10,  3]))\n",
      "tensor([0.1888])\n",
      "########################################################################################################################################################################################################\n",
      "text              Bisher bei Z Nation- Die sehen nicht wie Freiw...\n",
      "IMDB_ID                                                   tt4116866\n",
      "genre                                              [Action, Comedy]\n",
      "year                                                           2014\n",
      "duration                                                         44\n",
      "titleType                                                 tvEpisode\n",
      "primaryTitle                                     Doctor of the Dead\n",
      "isAdult                                                           0\n",
      "runtimeMinutes                                                   44\n",
      "averageRating                                                   8.6\n",
      "numVotes                                                        829\n",
      "Name: 4, dtype: object\n",
      "Bisher bei\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    index = i\n",
    "    print(df_val.iloc[index])\n",
    "    text = df_val.iloc[index].text\n",
    "    print(text[:10])\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True)\n",
    "    #inputs = inputs.to('cuda:0')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    print(torch.softmax(outputs.classification_logits, dim=-1).view(-1))\n",
    "    print(torch.sigmoid(outputs.multilabels_logits).view(-1).topk(k=3))\n",
    "    print(outputs.regression_logits.view(-1))\n",
    "    print(\"#\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9c4d68-8c90-4807-b608-0bf91d7822f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4377, 0.5623])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(outputs.classification_logits, dim=-1).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e1d7528-115d-4264-add8-86d006f3d2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.6503, 0.6386, 0.6247]),\n",
       "indices=tensor([12, 10,  3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(outputs.multilabels_logits).view(-1).topk(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9718fe30-034c-4151-b629-438392724057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1988])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.regression_logits.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c96df-36cb-48b2-bd16-e1361622be7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3cad689-4578-4a48-ac07-aeebfa207976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(16, 10).topk(k=3).indices.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee6e57-e46f-4a13-a6f4-ba742a33ff43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
