# Preface 

```{figure} ./figures/pika.jpeg
:name: Pika
:scale: 50%
:align: left

Hang in there
```

For the sake of readability, the listings in this text are shortened if necessary.
To take a look at the whole code, please visit the associated [GitHub-Repository](https://github.com/LennartKeller/trf_training_tut).

<br>
<br>
<br>
<br>
<br>

## TODOS

## Checklist for comparison

* GPU/ MultiGPU
* Checkpointing (with different strategies)
* Logging (Tensorboard, STDOUT, etc.)
* Other Tweaks:
    * Half precision
    * Gradient clipping
* Custom metrics
* Custom loss ...
* CLI Interface
* (Verwaltung und Vergleich mehrer Durchl√§ufe)
* Metadatenhandling 


### Code
* Get your head around metrics in Lightning
* Finalize training scripts
* Search for specials of each framework
* Implement checkpointing for each framework
* Check logging for each framework
* Get Argparse to work for each framwork

* Refactor common stuff into one submodule
    * Make scripts to module?

### Text

__Write as tutorial?__

* Finish experimental chapter
* Rework introduction
* Restructure huggingface intro and write more on huggingface models
* Start with Huggingface Trainer
* May Poutyne after that
* PyTorch-Lightning will take quite a while?

```{nb-exec-table}
```
